# -*- coding: utf-8 -*-
"""hci1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1P3Gg6mwU7cshgG2fuooZSpkJp7_kxyPD
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from prettytable import PrettyTable
from keras.preprocessing.text import Tokenizer
from keras.preprocessing.sequence import pad_sequences
from sklearn.model_selection import train_test_split
import pickle
from tensorflow.python.keras.layers import Dense
from tensorflow.python.keras import Sequential
!pip install tensorflow==1.14
import tensorflow as tf
print(tf.__version__)

base = 'drive/My Drive/'

df = pd.read_csv("master.csv", encoding='cp1252')
df = df.reindex(np.random.permutation(df.index))
df['content'] = df['content'].astype(str)

vocabulary_size = 200000
tokenizer = Tokenizer(num_words= 1000)
tokenizer.fit_on_texts(df['content'])

word2index = tokenizer.word_index
index2word = {i:j for i, j in enumerate(word2index)}

emotions = df.emotion.unique()
sum_categorical_emotions = [df[df.emotion == i].size for i in emotions]
plt.bar(emotions, sum_categorical_emotions)
plt.scatter(emotions, sum_categorical_emotions)
plt.grid(True)
plt.show()

df.head()

df.loc[df.emotion == 'guilt', 'emotion'] = 'disgust'
df.loc[df.emotion == 'disgust', 'emotion'] = 'disgust'
df.loc[df.emotion == 'shame', 'emotion'] = 'disgust'
df.loc[df.emotion == 'joy', 'emotion'] = 'happiness'
df.loc[df.emotion == 'love', 'emotion'] = 'happiness'
df.loc[df.emotion == 'truth', 'emotion'] = 'truth'
df.emotion.unique()

emotions = df.emotion.unique()
sum_categorical_emotions = [df[df.emotion == i].size for i in emotions]
print(sum_categorical_emotions)
plt.bar(emotions, sum_categorical_emotions)
plt.scatter(emotions, sum_categorical_emotions)
plt.grid(True)
plt.show()

from keras.models import Model
from keras.layers import LSTM, Activation, Dense, Dropout, Input, Embedding
from keras.optimizers import RMSprop
from keras.preprocessing.text import Tokenizer
from keras.preprocessing import sequence
from keras.utils import to_categorical

sequences = tokenizer.texts_to_sequences(df['content'])
data = pad_sequences(sequences, maxlen=50)
X = data.reshape(len(data), 50)
X[100]

flag = pd.Series(list(df['emotion']))
Y = pd.get_dummies(flag)
Y = np.array(Y)
Y[100]

X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.33, random_state=42)

inputs = Input(shape=[50])
layer = Embedding(100000, 500, input_length=50)(inputs)
layer = LSTM(512)(layer)
layer = Dense(256)(layer)
layer = Activation('relu')(layer)
layer = Dropout(0.5)(layer)
layer = Dense(7)(layer)
layer = Activation('softmax')(layer)
model = Model(inputs=inputs,outputs=layer)
model.summary()
model.compile(loss='categorical_crossentropy',optimizer="adam",metrics=['accuracy'])

history=model.fit(X_train, y_train, batch_size=8192, epochs=10, validation_data=(X_test, y_test), shuffle=True)

model.save('master_model.h5')

pickle.dump(history, open("history.p", "wb"))

from keras.models import load_model
model = load_model('master_model.h5')

statement = "i need assistance"
sequences = tokenizer.texts_to_sequences([statement])
data = pad_sequences(sequences, maxlen=50)
emotion = df.emotion.unique()
y = model.predict(data)
y = np.argmax(y)
print(emotion[y])